{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4512c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "#1. os\n",
    "#2. LangChain\n",
    "#3. JSON\n",
    "#4. Logging\n",
    "#5. openai\n",
    "#6. ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42082b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain import OpenAI, ConversationChain\n",
    "import json\n",
    "import logging\n",
    "from tabulate import tabulate\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0070981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input:hi there\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hi there\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Hello! How are you?\n",
      "User Input:i'm good\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi there\n",
      "AI:  Hi there! How can I help you?\n",
      "Human: i'm good\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-q5F9sjjDYIH1rbiCHBL15MCu on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-q5F9sjjDYIH1rbiCHBL15MCu on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-q5F9sjjDYIH1rbiCHBL15MCu on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "That's great to hear!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m     conversation\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39muser_input_lower)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(llm(user_input_lower))\n\u001b[1;32m---> 50\u001b[0m conv()\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36mconv\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# to take input for table\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         table_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m         table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter table name: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m         column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter column names separated by space: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m      8\u001b[0m         num_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the number of rows in the table: \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1179\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1180\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def conv():\n",
    "    \n",
    "    # to take input for table\n",
    "    \n",
    "        table_data = []\n",
    "        table_name = input(\"Enter table name: \")\n",
    "        column_names = input(\"Enter column names separated by space: \").split()\n",
    "        num_rows = int(input(\"Enter the number of rows in the table: \"))\n",
    "\n",
    "        # Prompt the user to input data for each row\n",
    "        for row_num in range(1, num_rows + 1):\n",
    "            print(f\"Row {row_num}:\")\n",
    "            row_values = input(\"Enter values separated by space: \").split()\n",
    "            row_dict = dict(zip(column_names, row_values))\n",
    "            table_data.append(row_dict)\n",
    "        \n",
    "        # To print table data in table format\n",
    "        print(tabulate(table_data, headers=\"keys\", tablefmt=\"pretty\"))\n",
    "\n",
    "        data_with_table_name = {\n",
    "            \"table_name\": table_name,\n",
    "            \"data\": table_data\n",
    "        }\n",
    "        \n",
    "        #converting table data list to json format\n",
    "        json_output = json.dumps(data_with_table_name, indent=2)\n",
    "        \n",
    "        #passing our query\n",
    "        user_query = input('Please enter the SQL query you want: ')\n",
    "        input_text = user_query + json_output\n",
    "        logging.info(\"User Query: %s\", user_query)\n",
    "        \n",
    "        \n",
    "        llm = OpenAI(temperature=0, model_name='text-davinci-003')\n",
    "        conversation = ConversationChain(llm=llm, verbose=True)\n",
    "        conversation.predict(input=input_text)\n",
    "        print(llm(input_text))\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input('User Input:')\n",
    "    llm = OpenAI(temperature=0, model_name='text-davinci-003')\n",
    "    conversation = ConversationChain(llm=llm, verbose=True)\n",
    "    conversation.predict(input=user_input)\n",
    "    print(llm(user_input))\n",
    "    user_input_lower = user_input.lower()\n",
    "    model_data = ['sql', 'query']\n",
    "    if any(keyword not in user_input_lower for keyword in model_data):\n",
    "        user_input_lower = (input('User Input:')).lower()\n",
    "        conversation.predict(input=user_input_lower)\n",
    "        print(llm(user_input_lower))\n",
    "    conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee7e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
